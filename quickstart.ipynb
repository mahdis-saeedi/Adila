{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/Adila/blob/main/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bold text**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Setup Python 3.8 in Colab**\n",
        "- No need to create an environment as we are already in an environment/container\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S-Z8LVcopmIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VyyZAufDhLXr",
        "outputId": "1f71f569-f325-4375-ddfe-e50360615cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\r                                                                               \rHit:4 https://cli.github.com/packages stable InRelease\n",
            "\r0% [2 InRelease 15.6 kB/128 kB 12%] [Waiting for headers] [Waiting for headers]\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,201 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,901 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,281 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,510 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,842 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,081 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,571 kB]\n",
            "Fetched 37.8 MB in 7s (5,783 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.10\n",
            "  libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3-dev python3-pkg-resources\n",
            "  python3-setuptools python3-wheel python3.10 python3.10-dev\n",
            "  python3.10-minimal python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-setuptools-doc python3.10-venv\n",
            "  python3.10-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.8-minimal\n",
            "  libpython3.8-stdlib python3-dev python3-pip python3-setuptools python3-wheel\n",
            "  python3.10-dev python3.8 python3.8-distutils python3.8-lib2to3\n",
            "  python3.8-minimal python3.8-venv\n",
            "The following packages will be upgraded:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3-pkg-resources python3.10 python3.10-minimal\n",
            "7 upgraded, 15 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 23.0 MB of archives.\n",
            "After this operation, 33.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.12 [4,763 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.12 [1,949 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.12 [508 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.12 [1,849 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.12 [2,268 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.12 [815 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.12 [508 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.7 [1,306 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-pkg-resources all 68.1.2-2~jammy3 [216 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools all 68.1.2-2~jammy3 [465 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 23.0 MB in 1s (16.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.10-dev_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking libpython3.10:amd64 (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Preparing to unpack .../02-python3.10_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.12) over (3.10.12-1~22.04.11) ...\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "Preparing to unpack .../06-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../07-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../08-javascript-common_11+nmu1_all.deb ...\n",
            "Unpacking javascript-common (11+nmu1) ...\n",
            "Selecting previously unselected package libjs-underscore.\n",
            "Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...\n",
            "Unpacking libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Selecting previously unselected package libjs-sphinxdoc.\n",
            "Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...\n",
            "Unpacking libjs-sphinxdoc (4.3.2-1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../11-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.10-dev.\n",
            "Preparing to unpack .../12-python3.10-dev_3.10.12-1~22.04.12_amd64.deb ...\n",
            "Unpacking python3.10-dev (3.10.12-1~22.04.12) ...\n",
            "Selecting previously unselected package python3-dev.\n",
            "Preparing to unpack .../13-python3-dev_3.10.6-1~22.04.1_amd64.deb ...\n",
            "Unpacking python3-dev (3.10.6-1~22.04.1) ...\n",
            "Preparing to unpack .../14-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../15-python3-setuptools_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../16-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../17-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../18-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../19-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../20-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../21-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up javascript-common (11+nmu1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.12) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Setting up python3.10-minimal (3.10.12-1~22.04.12) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.12) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-sphinxdoc (4.3.2-1) ...\n",
            "Setting up libpython3.10:amd64 (3.10.12-1~22.04.12) ...\n",
            "Setting up python3.10 (3.10.12-1~22.04.12) ...\n",
            "Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.12) ...\n",
            "Setting up python3.10-dev (3.10.12-1~22.04.12) ...\n",
            "Setting up python3-dev (3.10.6-1~22.04.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.8 python3.8-venv python3.8-distutils python3-pip\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W9EBY1-hLXt",
        "outputId": "11dc5bd8-3a45-40fa-82fe-0fe5088572d1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'adila/': No such file or directory\n",
            "Cloning into 'adila'...\n",
            "remote: Enumerating objects: 1617, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 1617 (delta 102), reused 102 (delta 68), pack-reused 1442 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1617/1617), 17.44 MiB | 14.22 MiB/s, done.\n",
            "Resolving deltas: 100% (855/855), done.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (75.3.2)\n",
            "Requirement already satisfied: hydra-core==1.3.2 in /usr/local/lib/python3.8/dist-packages (from -r adila/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.8/dist-packages (from -r adila/requirements.txt (line 2)) (1.24.4)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (6.4.5)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core==1.3.2->-r adila/requirements.txt (line 1)) (3.20.2)\n"
          ]
        }
      ],
      "source": [
        "!rm -R adila/\n",
        "!git clone --branch dev https://github.com/Fani-Lab/adila\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install -r adila/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**1. Running Adila**\n",
        "\n",
        "[`Hydra`](https://hydra.cc/) config overriding `data.*`, `fair.*`, and `eval.*` settings in [`Adila/src/__config__.yaml`](https://github.com/fani-lab/Adila/blob/main/src/__config__.yaml)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "  - `data.fteamsvecs`, the sparse matrix representation of the entire dataset (teams), including `['member']` and `['skill']`, each row showing a `team`\n",
        "  - `data.fsplits`, the train-test split rowids of `data.fteamsvecs`\n",
        "  - `data.fpred`, contains the member recommendations for each team in the test split, of size `|test|Ã—|member|`. The split file is necessary to know these recommendations are for what teams in the dataset\n",
        "  \n",
        "  These files can be obtained from by runnig `OpeNTF` team recommendation library at [`OpeNTF`](https://github.com/fani-lab/OpeNTF) like for the `toy.dblp` dataset at [`OpeNTF/data/dblp/toy.dblp.v12.json`](https://github.com/fani-lab/OpeNTF/tree/main/data/dblp/toy.dblp.v12.json).\n",
        "  \n",
        "  Adila codebase already included them at [`Adila/output/dblp/toy.dblp.v12.json`](https://github.com/fani-lab/Adila/tree/main/output/dblp/toy.dblp.v12.json)\n",
        "  - `data.fgender`, contains the `female` member ids as the `minority` also `protected` group.\n",
        "  \n",
        "  In `Adila`, we keep the labels of `minority` group for efficiency as they are very few relative to majority group. However, `protected` group could be the same as `minority` group, like in `gender` protected attribute, or the `majority` group (non-popular experts, who are more often than popular ones), like in `popularity` protected attribute.\n",
        "\n",
        "  - `data.output`, which is the path of generated files. As seen in the codebase, it is suggested to follow same folder structure as in [`OpeNTF`](https://github.com/fani-lab/OpeNTF) to avoid conflicts between prediction files of different baselines.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "data:\n",
        "  fteamsvecs: ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl\n",
        "  fgender: ../output/dblp/toy.dblp.v12.json/females.csv\n",
        "  fsplits: ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl\n",
        "  fpred: ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred\n",
        "  output: ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "  - `fair.algorithm`, reranking algorithm from `det_greedy`, `det_cons`, `det_relaxed`, `det_const_sort`, `fa-ir`\n",
        "  - `notion`, notion of fairness, from equality of odds (`eo`), demographic parity (`dp`)\n",
        "  - `k_max`, cutoff for the reranking algorithms\n",
        "  - `attribute`, the protected attribute from `popularity`, `gender`\n",
        "  - `is_popular_alg`, popularity status based on either `avg` teams per experts, i.e., whoever above this value is popular, or `auc` whoever is in the head of distribution figure\n",
        "  - `alpha`, the significance value for fa-ir algorithm\n",
        "\n",
        "\n",
        "```\n",
        "fair:\n",
        "  algorithm: det_greedy\n",
        "  notion: eo\n",
        "  k_max: 5\n",
        "  attribute: popularity\n",
        "  is_popular_alg: avg\n",
        "  alpha: 0.1\n",
        "```\n",
        "---\n",
        "\n",
        "  - `per_instance`, metric value for each test instance of team, needed for paired significance tests\n",
        "  - `fair_metrics`, metrics to measure fairness of the recommended members for the test teams\n",
        "  - `utility_metrics`, metrics to measure accuracy of the recommended members for the test teams\n",
        "  - `topk`, cutoff for the top-k recommended members\n",
        "  - `trec`, ranking metrics from `trec_eval`. See the complete list at [`pytrec_eval`](https://github.com/terrierteam/pytrec_eval/blob/master/tests/pytrec_eval_tests.py)\n",
        "\n",
        "```\n",
        "eval:\n",
        "  per_instance: True\n",
        "  fair_metrics: [ndkl, skew]\n",
        "  utility_metrics:\n",
        "    topk: '2,5'\n",
        "    trec: [P_topk, recall_topk, ndcg_cut_topk, map_cut_topk, success_topk]\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QWdZXHDwqPcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr3rpQkXihw9",
        "outputId": "82ba3c13-a1ed-4d49-b7a9-85d168c7f175",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/adila/src/adila/src/adila/src\n",
            "[2025-12-07 03:57:26,653][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:26,684][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:26,684][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:26,686][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 664.10it/s]\n",
            "[2025-12-07 03:57:26,852][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:26,861][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:26,861][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:26,868][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:26,888][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1485.97it/s]\n",
            "[2025-12-07 03:57:26,916][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:26,917][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:26,920][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:26,921][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:26,922][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2793.60it/s]\n",
            "[2025-12-07 03:57:26,931][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:26,938][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:26,939][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:26,945][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:26,954][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2102.20it/s]\n",
            "[2025-12-07 03:57:26,967][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:26,968][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:26,971][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:26,971][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:26,973][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2919.60it/s]\n",
            "[2025-12-07 03:57:26,981][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:26,989][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:26,989][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:26,995][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,005][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1792.13it/s]\n",
            "[2025-12-07 03:57:27,017][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,018][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,021][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,021][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,023][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2039.04it/s]\n",
            "[2025-12-07 03:57:27,033][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,040][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,040][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,046][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,056][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2405.54it/s]\n",
            "[2025-12-07 03:57:27,065][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,066][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,069][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,070][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,073][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2711.95it/s]\n",
            "[2025-12-07 03:57:27,082][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,087][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,088][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,092][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,099][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2758.68it/s]\n",
            "[2025-12-07 03:57:27,109][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,110][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,114][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,114][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,116][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 1385.91it/s]\n",
            "[2025-12-07 03:57:27,130][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,138][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,138][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,143][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,153][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2121.34it/s]\n",
            "[2025-12-07 03:57:27,163][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,164][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,168][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,168][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,170][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2785.80it/s]\n",
            "[2025-12-07 03:57:27,178][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,186][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,186][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,192][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,201][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2441.10it/s]\n",
            "[2025-12-07 03:57:27,235][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,239][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,256][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,256][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,259][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3390.71it/s]\n",
            "[2025-12-07 03:57:27,267][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,274][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,274][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,281][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,292][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2709.50it/s]\n",
            "[2025-12-07 03:57:27,302][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,303][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,306][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using fa-ir with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,306][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,308][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3548.48it/s]\n",
            "[2025-12-07 03:57:27,315][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,324][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,325][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,334][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,346][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2146.52it/s]\n",
            "[2025-12-07 03:57:27,357][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,358][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,361][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,361][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,363][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3381.96it/s]\n",
            "[2025-12-07 03:57:27,371][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,378][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,378][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,383][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,392][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2443.38it/s]\n",
            "[2025-12-07 03:57:27,403][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,404][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,407][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,407][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,409][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2740.66it/s]\n",
            "[2025-12-07 03:57:27,418][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,426][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,426][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,431][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,441][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2364.85it/s]\n",
            "[2025-12-07 03:57:27,451][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,453][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,456][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,456][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,457][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3596.56it/s]\n",
            "[2025-12-07 03:57:27,465][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,473][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,473][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,479][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,488][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2104.73it/s]\n",
            "[2025-12-07 03:57:27,499][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,499][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,502][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,503][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,504][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3625.15it/s]\n",
            "[2025-12-07 03:57:27,512][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,519][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,519][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,524][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,534][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2359.80it/s]\n",
            "[2025-12-07 03:57:27,545][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,546][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,549][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,549][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,551][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3436.26it/s]\n",
            "[2025-12-07 03:57:27,559][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,566][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,567][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,572][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,582][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2345.28it/s]\n",
            "[2025-12-07 03:57:27,591][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,592][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,595][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,595][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,597][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3616.40it/s]\n",
            "[2025-12-07 03:57:27,604][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,611][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,612][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,617][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,629][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1150.95it/s]\n",
            "[2025-12-07 03:57:27,647][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,649][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,652][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,652][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,654][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3646.59it/s]\n",
            "[2025-12-07 03:57:27,661][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,668][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,668][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,674][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,683][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2350.01it/s]\n",
            "[2025-12-07 03:57:27,695][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,696][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,699][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_greedy with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,700][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,701][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3527.00it/s]\n",
            "[2025-12-07 03:57:27,709][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,716][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,716][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,722][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,731][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2418.30it/s]\n",
            "[2025-12-07 03:57:27,742][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,743][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,746][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,746][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,747][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3568.41it/s]\n",
            "[2025-12-07 03:57:27,755][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,762][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,762][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,768][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,777][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2209.85it/s]\n",
            "[2025-12-07 03:57:27,787][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,788][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,791][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,791][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,793][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3091.32it/s]\n",
            "[2025-12-07 03:57:27,803][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,812][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,813][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,820][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,832][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1312.94it/s]\n",
            "[2025-12-07 03:57:27,848][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,850][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,855][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,855][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,858][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2203.59it/s]\n",
            "[2025-12-07 03:57:27,867][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,875][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,875][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,881][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,892][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1938.04it/s]\n",
            "[2025-12-07 03:57:27,904][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,905][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,909][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,909][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,911][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3229.37it/s]\n",
            "[2025-12-07 03:57:27,920][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,927][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,927][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,932][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,942][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2394.56it/s]\n",
            "[2025-12-07 03:57:27,952][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:27,953][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:27,956][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:27,956][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:27,958][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3576.32it/s]\n",
            "[2025-12-07 03:57:27,965][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:27,975][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:27,975][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:27,981][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:27,989][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2411.35it/s]\n",
            "[2025-12-07 03:57:27,999][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,000][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,003][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,003][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,005][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3686.33it/s]\n",
            "[2025-12-07 03:57:28,013][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,019][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,020][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,025][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,035][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1577.87it/s]\n",
            "[2025-12-07 03:57:28,048][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,049][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,052][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,052][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,054][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2967.53it/s]\n",
            "[2025-12-07 03:57:28,062][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,068][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,069][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,074][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,083][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2414.96it/s]\n",
            "[2025-12-07 03:57:28,093][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,094][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,097][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,097][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,098][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3642.15it/s]\n",
            "[2025-12-07 03:57:28,106][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,113][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,113][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,118][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,128][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2415.80it/s]\n",
            "[2025-12-07 03:57:28,138][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,139][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,142][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,142][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,143][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3657.40it/s]\n",
            "[2025-12-07 03:57:28,151][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,158][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,158][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,164][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,173][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2404.16it/s]\n",
            "[2025-12-07 03:57:28,183][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,183][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,186][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,186][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,188][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3850.81it/s]\n",
            "[2025-12-07 03:57:28,195][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,202][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,202][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,207][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,216][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2447.09it/s]\n",
            "[2025-12-07 03:57:28,226][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,227][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,230][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,230][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,232][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2329.39it/s]\n",
            "[2025-12-07 03:57:28,241][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,248][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,248][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,254][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,264][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2350.01it/s]\n",
            "[2025-12-07 03:57:28,274][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,275][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,278][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,279][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,280][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3658.67it/s]\n",
            "[2025-12-07 03:57:28,288][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,295][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,295][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,300][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,309][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2300.27it/s]\n",
            "[2025-12-07 03:57:28,320][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,320][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,323][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,323][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,325][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3739.57it/s]\n",
            "[2025-12-07 03:57:28,333][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,340][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,340][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,346][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,355][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2397.29it/s]\n",
            "[2025-12-07 03:57:28,365][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,366][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,369][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,369][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,371][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3594.09it/s]\n",
            "[2025-12-07 03:57:28,379][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,385][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,386][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,391][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,400][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2431.48it/s]\n",
            "[2025-12-07 03:57:28,411][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,412][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,415][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,415][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,417][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3472.11it/s]\n",
            "[2025-12-07 03:57:28,425][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,433][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,433][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,442][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,453][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2081.13it/s]\n",
            "[2025-12-07 03:57:28,466][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,468][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,474][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,474][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,477][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3552.69it/s]\n",
            "[2025-12-07 03:57:28,485][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,491][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,492][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,497][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,506][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1973.98it/s]\n",
            "[2025-12-07 03:57:28,517][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,518][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,521][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,521][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,522][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3782.06it/s]\n",
            "[2025-12-07 03:57:28,530][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,537][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,537][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,542][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,552][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2362.99it/s]\n",
            "[2025-12-07 03:57:28,561][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,562][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,565][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,565][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,567][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3711.12it/s]\n",
            "[2025-12-07 03:57:28,575][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,582][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,582][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,588][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,598][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2324.23it/s]\n",
            "[2025-12-07 03:57:28,609][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,609][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,613][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,613][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,615][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3171.26it/s]\n",
            "[2025-12-07 03:57:28,623][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,632][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,632][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,639][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,650][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2040.63it/s]\n",
            "[2025-12-07 03:57:28,661][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,662][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,665][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,666][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,669][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 1392.07it/s]\n",
            "[2025-12-07 03:57:28,681][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,688][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,688][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,694][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,704][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2028.59it/s]\n",
            "[2025-12-07 03:57:28,716][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,717][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,720][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,721][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,722][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2634.94it/s]\n",
            "[2025-12-07 03:57:28,733][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,740][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,740][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,746][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,756][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2063.11it/s]\n",
            "[2025-12-07 03:57:28,768][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,769][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,772][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,772][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,774][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 1881.70it/s]\n",
            "[2025-12-07 03:57:28,784][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,793][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,793][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,799][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,809][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2408.58it/s]\n",
            "[2025-12-07 03:57:28,821][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/dp/f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,822][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,825][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,825][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,827][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 3534.13it/s]\n",
            "[2025-12-07 03:57:28,834][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,845][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,845][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,856][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,871][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1966.20it/s]\n",
            "[2025-12-07 03:57:28,887][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2025-12-07 03:57:28,888][__main__][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "main.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2025-12-07 03:57:28,894][__main__][INFO] - \u001b[94mReranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using det_cons with 5 cutoff ...\u001b[0m\n",
            "[2025-12-07 03:57:28,894][__main__][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2025-12-07 03:57:28,897][__main__][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 5 cutoff ...\u001b[0m\n",
            "5it [00:00, 2792.11it/s]\n",
            "[2025-12-07 03:57:28,908][__main__][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2025-12-07 03:57:28,917][__main__][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred using {'topk': '1,2,${fair.k_max}', 'trec': ['P_1,2,5', 'recall_1,2,5', 'ndcg_cut_1,2,5', 'map_cut_1,2,5', 'success_1,2,5'], 'other': []} ... \u001b[0m\n",
            "[2025-12-07 03:57:28,917][__main__][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2025-12-07 03:57:28,924][__main__][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2025-12-07 03:57:28,934][metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2111.09it/s]\n",
            "[2025-12-07 03:57:28,947][__main__][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n"
          ]
        }
      ],
      "source": [
        "%cd adila/src/\n",
        "!python main.py data.fpred=../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred fair.algorithm=fa-ir fair.notion=eo fair.attribute=popularity fair.is_popular_alg=avg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "\n",
        "- `adila/{popularity,gender}/stats.pkl`, the distribution of popular/non-popular, or male/female experts in the entire dataset\n",
        "- `adila/{popularity,gender}/labels.csv`, the ids for popular or female experts. While the female ids are fixed and obtained from the `data.fgender` file, the popular ids depends on `is_popular_alg` and is calculated based on the data distribution\n",
        "\n",
        "- `adila/{popularity,gender}/{notion}`, the subfolder containg the results based on the fairness notion\n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred`, the reranked version of the recommended members from `data.fpred`\n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.fair.instance.csv`, the fairness metric values for `data.fpred` (before) and the reranked version (after) per each team instance in the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.fair.mean.csv`, the average of fairness metric values for `data.fpred` (before) and the reranked version (after) over all teams of the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.utility.instance.csv`, the accuracy metric values for `data.fpred` (before) and the reranked version (after) per each team instance in the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.utility.mean.csv`, the average of accuracy metric values for `data.fpred` (before) and the reranked version (after) over all teams of the test set"
      ],
      "metadata": {
        "id": "lmgkO6YU1boK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ktJb2ghLXu",
        "outputId": "574bcdc8-be0e-4a58-c382-16c1ef205199",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   \n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ popularity\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stats.pkl\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ labels.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ eo\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ratios.pkl\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dp\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gender\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ stats.pkl\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ labels.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ eo\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ratios.pkl\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dp\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n"
          ]
        }
      ],
      "source": [
        "!find ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/ -print | sed 's;[^/]*/;â”‚   ;g;s;â”‚   \\([^â”‚]\\);â”œâ”€â”€ \\1;'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average fairness measures**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0XPjutdQ4_dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv', index_col=0)"
      ],
      "metadata": {
        "id": "afwtkamt5moP",
        "outputId": "aecb20c0-a5f0-4d9f-e249-ba0c3d03ed55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          mean\n",
              "metrics                       \n",
              "before.ndkl           0.289672\n",
              "after.ndkl            0.140630\n",
              "before.skew.minority -9.715486\n",
              "before.skew.majority -0.028526\n",
              "after.skew.minority  -9.715486\n",
              "after.skew.majority  -0.028526"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3488469f-8123-4ed1-ba4b-b8eebbe70a9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>before.ndkl</th>\n",
              "      <td>0.289672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after.ndkl</th>\n",
              "      <td>0.140630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before.skew.minority</th>\n",
              "      <td>-9.715486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before.skew.majority</th>\n",
              "      <td>-0.028526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after.skew.minority</th>\n",
              "      <td>-9.715486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after.skew.majority</th>\n",
              "      <td>-0.028526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3488469f-8123-4ed1-ba4b-b8eebbe70a9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3488469f-8123-4ed1-ba4b-b8eebbe70a9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3488469f-8123-4ed1-ba4b-b8eebbe70a9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76d917de-413c-4e35-bff6-1615cfd1e7ba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76d917de-413c-4e35-bff6-1615cfd1e7ba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76d917de-413c-4e35-bff6-1615cfd1e7ba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"metrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"before.ndkl\",\n          \"after.ndkl\",\n          \"after.skew.majority\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.06663334106197,\n        \"min\": -9.715486100844831,\n        \"max\": 0.289672380875757,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1406301531400426,\n          -0.0285256151306606,\n          0.289672380875757\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fairness measures per each test team**"
      ],
      "metadata": {
        "id": "fIdoGfzC7EVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv')"
      ],
      "metadata": {
        "id": "wfpmBbgv6CEx",
        "outputId": "dade565a-7ed1-46bb-b916-934acb2a3551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   before.ndkl  after.ndkl  before.skew.minority  before.skew.majority  \\\n",
              "0     0.105361    0.105361            -25.328436              0.105361   \n",
              "1     0.105361    0.105361            -25.328436              0.105361   \n",
              "2     0.095459    0.095459              0.693147             -0.117783   \n",
              "3     0.943696    0.198485              0.693147             -0.117783   \n",
              "4     0.198485    0.198485              0.693147             -0.117783   \n",
              "\n",
              "   after.skew.minority  after.skew.majority  \n",
              "0           -25.328436             0.105361  \n",
              "1           -25.328436             0.105361  \n",
              "2             0.693147            -0.117783  \n",
              "3             0.693147            -0.117783  \n",
              "4             0.693147            -0.117783  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30b2a1a1-489d-447f-a98f-3099ef92b110\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>before.ndkl</th>\n",
              "      <th>after.ndkl</th>\n",
              "      <th>before.skew.minority</th>\n",
              "      <th>before.skew.majority</th>\n",
              "      <th>after.skew.minority</th>\n",
              "      <th>after.skew.majority</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.105361</td>\n",
              "      <td>0.105361</td>\n",
              "      <td>-25.328436</td>\n",
              "      <td>0.105361</td>\n",
              "      <td>-25.328436</td>\n",
              "      <td>0.105361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.105361</td>\n",
              "      <td>0.105361</td>\n",
              "      <td>-25.328436</td>\n",
              "      <td>0.105361</td>\n",
              "      <td>-25.328436</td>\n",
              "      <td>0.105361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.095459</td>\n",
              "      <td>0.095459</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.943696</td>\n",
              "      <td>0.198485</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.198485</td>\n",
              "      <td>0.198485</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.117783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30b2a1a1-489d-447f-a98f-3099ef92b110')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30b2a1a1-489d-447f-a98f-3099ef92b110 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30b2a1a1-489d-447f-a98f-3099ef92b110');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-17e4cac0-90b2-47df-89a2-e2281b5417e4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17e4cac0-90b2-47df-89a2-e2281b5417e4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-17e4cac0-90b2-47df-89a2-e2281b5417e4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"before.ndkl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3680090888505523,\n        \"min\": 0.0954594565143331,\n        \"max\": 0.9436962776137968,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0954594565143331,\n          0.1984851389352248,\n          0.1053605156577152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.ndkl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05296858798534027,\n        \"min\": 0.0954594565143331,\n        \"max\": 0.1984851389352248,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1053605156577152,\n          0.0954594565143331,\n          0.1984851389352248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"before.skew.minority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.252608102554191,\n        \"min\": -25.3284360229445,\n        \"max\": 0.6931471805549453,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6931471805549453,\n          -25.3284360229445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"before.skew.majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1222207566164673,\n        \"min\": -0.1177830356562445,\n        \"max\": 0.1053605156577152,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.1177830356562445,\n          0.1053605156577152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.skew.minority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.252608102554191,\n        \"min\": -25.3284360229445,\n        \"max\": 0.6931471805549453,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6931471805549453,\n          -25.3284360229445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.skew.majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1222207566164673,\n        \"min\": -0.1177830356562445,\n        \"max\": 0.1053605156577152,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.1177830356562445,\n          0.1053605156577152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average accuracy values (Utility)**\n"
      ],
      "metadata": {
        "id": "GwYM3i9e6KyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "id": "3OguPqka6Hrl",
        "outputId": "2cd0d8ca-d193-4468-f6d7-cca0372a16e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            mean.before  mean.after\n",
              "metric                             \n",
              "P_1            0.200000    0.200000\n",
              "P_2            0.200000    0.200000\n",
              "P_5            0.120000    0.120000\n",
              "recall_1       0.100000    0.100000\n",
              "recall_2       0.200000    0.200000\n",
              "recall_5       0.300000    0.300000\n",
              "ndcg_cut_1     0.200000    0.200000\n",
              "ndcg_cut_2     0.200000    0.200000\n",
              "ndcg_cut_5     0.252814    0.252814\n",
              "map_cut_1      0.100000    0.100000\n",
              "map_cut_2      0.150000    0.150000\n",
              "map_cut_5      0.175000    0.175000\n",
              "success_1      0.200000    0.200000\n",
              "success_2      0.400000    0.400000\n",
              "success_5      0.600000    0.600000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27b087be-d9dd-4fa7-96fa-5c3ba505f06b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean.before</th>\n",
              "      <th>mean.after</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_1</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_1</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_1</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.252814</td>\n",
              "      <td>0.252814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_1</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_1</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_2</th>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_5</th>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27b087be-d9dd-4fa7-96fa-5c3ba505f06b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27b087be-d9dd-4fa7-96fa-5c3ba505f06b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27b087be-d9dd-4fa7-96fa-5c3ba505f06b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d7d4817-9cda-4100-8362-d1dab55c550f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d7d4817-9cda-4100-8362-d1dab55c550f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d7d4817-9cda-4100-8362-d1dab55c550f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"map_cut_1\",\n          \"map_cut_5\",\n          \"P_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12866454175705333,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.4,\n          0.12,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12866454175705333,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.4,\n          0.12,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy values per each test team (Utility)**\n"
      ],
      "metadata": {
        "id": "fHxFVLr16cN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv')"
      ],
      "metadata": {
        "id": "UN5XfxuG6iyO",
        "outputId": "f14cc4e5-4891-4392-fe67-4cddc14e9c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   P_1.before  P_2.before  P_5.before  recall_1.before  recall_2.before  \\\n",
              "0         0.0         0.0         0.0              0.0              0.0   \n",
              "1         1.0         0.5         0.2              0.5              0.5   \n",
              "2         0.0         0.0         0.0              0.0              0.0   \n",
              "3         0.0         0.0         0.2              0.0              0.0   \n",
              "4         0.0         0.5         0.2              0.0              0.5   \n",
              "\n",
              "   recall_5.before  ndcg_cut_1.before  ndcg_cut_2.before  ndcg_cut_5.before  \\\n",
              "0              0.0                0.0            0.00000            0.00000   \n",
              "1              0.5                1.0            0.61315            0.61315   \n",
              "2              0.0                0.0            0.00000            0.00000   \n",
              "3              0.5                0.0            0.00000            0.26407   \n",
              "4              0.5                0.0            0.38685            0.38685   \n",
              "\n",
              "   map_cut_1.before  ...  recall_5.after  ndcg_cut_1.after  ndcg_cut_2.after  \\\n",
              "0               0.0  ...             0.0               0.0           0.00000   \n",
              "1               0.5  ...             0.5               1.0           0.61315   \n",
              "2               0.0  ...             0.0               0.0           0.00000   \n",
              "3               0.0  ...             0.5               0.0           0.00000   \n",
              "4               0.0  ...             0.5               0.0           0.38685   \n",
              "\n",
              "   ndcg_cut_5.after  map_cut_1.after  map_cut_2.after  map_cut_5.after  \\\n",
              "0           0.00000              0.0             0.00            0.000   \n",
              "1           0.61315              0.5             0.50            0.500   \n",
              "2           0.00000              0.0             0.00            0.000   \n",
              "3           0.26407              0.0             0.00            0.125   \n",
              "4           0.38685              0.0             0.25            0.250   \n",
              "\n",
              "   success_1.after  success_2.after  success_5.after  \n",
              "0              0.0              0.0              0.0  \n",
              "1              1.0              1.0              1.0  \n",
              "2              0.0              0.0              0.0  \n",
              "3              0.0              0.0              1.0  \n",
              "4              0.0              1.0              1.0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-771ab448-188b-4e83-8479-d8edfc1d517b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P_1.before</th>\n",
              "      <th>P_2.before</th>\n",
              "      <th>P_5.before</th>\n",
              "      <th>recall_1.before</th>\n",
              "      <th>recall_2.before</th>\n",
              "      <th>recall_5.before</th>\n",
              "      <th>ndcg_cut_1.before</th>\n",
              "      <th>ndcg_cut_2.before</th>\n",
              "      <th>ndcg_cut_5.before</th>\n",
              "      <th>map_cut_1.before</th>\n",
              "      <th>...</th>\n",
              "      <th>recall_5.after</th>\n",
              "      <th>ndcg_cut_1.after</th>\n",
              "      <th>ndcg_cut_2.after</th>\n",
              "      <th>ndcg_cut_5.after</th>\n",
              "      <th>map_cut_1.after</th>\n",
              "      <th>map_cut_2.after</th>\n",
              "      <th>map_cut_5.after</th>\n",
              "      <th>success_1.after</th>\n",
              "      <th>success_2.after</th>\n",
              "      <th>success_5.after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.26407</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.26407</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-771ab448-188b-4e83-8479-d8edfc1d517b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-771ab448-188b-4e83-8479-d8edfc1d517b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-771ab448-188b-4e83-8479-d8edfc1d517b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35f5ca1c-6ff6-403f-b3bd-557be6908cf3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35f5ca1c-6ff6-403f-b3bd-557be6908cf3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35f5ca1c-6ff6-403f-b3bd-557be6908cf3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
